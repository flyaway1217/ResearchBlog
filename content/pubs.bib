@inproceedings{weston2011wsabie,
  title={{Wsabie: Scaling up to large vocabulary image annotation}},
  author={Weston, Jason and Bengio, Samy and Usunier, Nicolas},
  booktitle={Twenty-Second International Joint Conference on Artificial Intelligence},
  year={2011}
}

@article{mikolov2013efficient,
  title={{Efficient estimation of word representations in vector space}},
  author={Mikolov, Tomas and Chen, Kai and Corrado, Greg and Dean, Jeffrey},
  journal={arXiv preprint arXiv:1301.3781},
  year={2013}
}

@article{firth1935technique,
  title={{The Technique of Semantics.}},
  author={Firth, John Rupert},
  journal={Transactions of the philological society},
  volume={34},
  number={1},
  pages={36--73},
  year={1935},
  publisher={Wiley Online Library}
}


@article{rumelhart1987parallel,
  title={{Parallel distributed processing, explotation in the microstructure of cognition-Vol. 1: Foundations}},
  author={Rumelhart, David E and McClelland, James L},
  journal={pdpe},
  year={1987}
}

@article{bengio2003neural,
  title={{A neural probabilistic language model}},
  author={Bengio, Yoshua and Ducharme, R{\'e}jean and Vincent, Pascal and Jauvin, Christian},
  journal={Journal of machine learning research},
  volume={3},
  number={Feb},
  pages={1137--1155},
  year={2003}
}

@inproceedings{devlin2019bert,
  title={{BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding}},
  author={Devlin, Jacob and Chang, Ming-Wei and Lee, Kenton and Toutanova, Kristina},
  booktitle={Proceedings of the 2019 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies, Volume 1 (Long and Short Papers)},
  pages={4171--4186},
  year={2019}
}
@article{bojanowski2017enriching,
  title={{Enriching word vectors with subword information}},
  author={Bojanowski, Piotr and Grave, Edouard and Joulin, Armand and Mikolov, Tomas},
  journal={Transactions of the Association for Computational Linguistics},
  volume={5},
  pages={135--146},
  year={2017},
  publisher={MIT Press}
}

@article{ganesh2020compressing,
title={Compressing large-scale transformer-based models: A case study on bert},
author={Ganesh, Prakhar and Chen, Yao and Lou, Xin and Khan, Mohammad Ali and Yang, Yin and Chen, Deming and Winslett, Marianne and Sajjad, Hassan and Nakov, Preslav},
journal={arXiv preprint arXiv:2002.11985},
year={2020}
}

@inproceedings{jacob2018quantization,
  title={Quantization and Training of Neural Networks for Efficient Integer-Arithmetic-Only Inference},
  author={Jacob, Benoit and Kligys, Skirmantas and Chen, Bo and Zhu, Menglong and Tang, Matthew and Howard, Andrew and Adam, Hartwig and Kalenichenko, Dmitry},
  booktitle={2018 IEEE/CVF Conference on Computer Vision and Pattern Recognition},
  pages={2704--2713},
  year={2018},
  organization={IEEE}
}

@article{zafrir2019q8bert,
title={Q8bert: Quantized 8bit bert},
author={Zafrir, Ofir and Boudoukh, Guy and Izsak, Peter and Wasserblat, Moshe},
journal={arXiv preprint arXiv:1910.06188},
year={2019}
}

@inproceedings{shen2020q,
title={Q-BERT: Hessian Based Ultra Low Precision Quantization of BERT.},
author={Shen, Sheng and Dong, Zhen and Ye, Jiayu and Ma, Linjian and Yao, Zhewei and Gholami, Amir and Mahoney, Michael W and Keutzer, Kurt},
booktitle={AAAI},
pages={8815–8821},
year={2020}
}

@article{fan2020training,
title={Training with quantization noise for extreme model compression},
author={Fan, Angela and Stock, Pierre and Graham, Benjamin and Grave, Edouard and Gribonval, R{'e}mi and J{'e}gou, Herv{'e} and Joulin, Armand},
journal={ArXiv, abs/2004.07320},
year={2020}
}

@inproceedings{kovaleva2019revealing,
title={Revealing the Dark Secrets of BERT},
author={Kovaleva, Olga and Romanov, Alexey and Rogers, Anna and Rumshisky, Anna},
booktitle={Proceedings of the 2019 Conference on Empirical Methods in Natural Language Processing and the 9th International Joint Conference on Natural Language Processing (EMNLP-IJCNLP)},
pages={4365–4374},
year={2019}
}

@inproceedings{michel2019sixteen,
title={Are sixteen heads really better than one?},
author={Michel, Paul and Levy, Omer and Neubig, Graham},
booktitle={Advances in Neural Information Processing Systems},
pages={14014–14024},
year={2019}
}

@inproceedings{voita2019analyzing,
title={Analyzing Multi-Head Self-Attention: Specialized Heads Do the Heavy Lifting, the Rest Can Be Pruned},
author={Voita, Elena and Talbot, David and Moiseev, Fedor and Sennrich, Rico and Titov, Ivan},
booktitle={Proceedings of the 57th Annual Meeting of the Association for Computational Linguistics},
pages={5797–5808},
year={2019}
}

@article{gordon2020compressing,
title={Compressing BERT: Studying the effects of weight pruning on transfer learning},
author={Gordon, Mitchell A and Duh, Kevin and Andrews, Nicholas},
journal={arXiv preprint arXiv:2002.08307},
year={2020}
}

@article{guo2019reweighted,
title={Reweighted proximal pruning for large-scale language representation},
author={Guo, Fu-Ming and Liu, Sijia and Mungall, Finlay S and Lin, Xue and Wang, Yanzhi},
journal={arXiv preprint arXiv:1909.12486},
year={2019}
}

@article{sanh2020movement,
title={Movement Pruning: Adaptive Sparsity by Fine-Tuning},
author={Sanh, Victor and Wolf, Thomas and Rush, Alexander M},
journal={arXiv preprint arXiv:2005.07683},
year={2020}
}

@article{raganato2020fixed,
title={Fixed encoder self-attention patterns in transformer-based machine translation},
author={Raganato, Alessandro and Scherrer, Yves and Tiedemann, J{"o}rg},
journal={arXiv preprint arXiv:2002.10260},
year={2020}
}

@article{fan2019reducing,
title={Reducing transformer depth on demand with structured dropout},
author={Fan, Angela and Grave, Edouard and Joulin, Armand},
journal={arXiv preprint arXiv:1909.11556},
year={2019}
}

@article{wang2019structured,
title={Structured pruning of large language models},
author={Wang, Ziheng and Wohlwend, Jeremy and Lei, Tao},
journal={arXiv preprint arXiv:1910.04732},
year={2019}
}

@inproceedings{ott2018scaling,
  title={Scaling Neural Machine Translation},
  author={Ott, Myle and Edunov, Sergey and Grangier, David and Auli, Michael},
  booktitle={Proceedings of the Third Conference on Machine Translation: Research Papers},
  pages={1--9},
  year={2018}
}

@inproceedings{han2015learning,
  title={Learning both weights and connections for efficient neural networks},
  author={Han, Song and Pool, Jeff and Tran, John and Dally, William J},
  booktitle={Proceedings of the 28th International Conference on Neural Information Processing Systems-Volume 1},
  pages={1135--1143},
  year={2015}
}

@inproceedings{williams2018broad,
  title={A Broad-Coverage Challenge Corpus for Sentence Understanding through Inference},
  author={Williams, Adina and Nangia, Nikita and Bowman, Samuel},
  booktitle={Proceedings of the 2018 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies, Volume 1 (Long Papers)},
  pages={1112--1122},
  year={2018}
}

@inproceedings{rajpurkar2016squad,
  title={SQuAD: 100,000+ Questions for Machine Comprehension of Text},
  author={Rajpurkar, Pranav and Zhang, Jian and Lopyrev, Konstantin and Liang, Percy},
  booktitle={Proceedings of the 2016 Conference on Empirical Methods in Natural Language Processing},
  pages={2383--2392},
  year={2016}
}

@article{liu2019roberta,
  title={RoBERTa: A Robustly Optimized BERT Pretraining Approach},
  author={Liu, Yinhan and Ott, Myle and Goyal, Naman and Du, Jingfei and Joshi, Mandar and Chen, Danqi and Levy, Omer and Lewis, Mike and Zettlemoyer, Luke and Stoyanov, Veselin},
  journal={arXiv},
  pages={arXiv--1907},
  year={2019}
}

@inproceedings{yang2019xlnet,
  title={Xlnet: Generalized autoregressive pretraining for language understanding},
  author={Yang, Zhilin and Dai, Zihang and Yang, Yiming and Carbonell, Jaime and Salakhutdinov, Russ R and Le, Quoc V},
  booktitle={Advances in neural information processing systems},
  pages={5753--5763},
  year={2019}
}

@inproceedings{kim-etal-2019-probing,
    title = "Probing What Different {NLP} Tasks Teach Machines about Function Word Comprehension",
    author = "Kim, Najoung  and
      Patel, Roma  and
      Poliak, Adam  and
      Xia, Patrick  and
      Wang, Alex  and
      McCoy, Tom  and
      Tenney, Ian  and
      Ross, Alexis  and
      Linzen, Tal  and
      Van Durme, Benjamin  and
      Bowman, Samuel R.  and
      Pavlick, Ellie",
    booktitle = "Proceedings of the Eighth Joint Conference on Lexical and Computational Semantics (*{SEM} 2019)",
    month = jun,
    year = "2019",
    address = "Minneapolis, Minnesota",
    publisher = "Association for Computational Linguistics",
    url = "https://www.aclweb.org/anthology/S19-1026",
    doi = "10.18653/v1/S19-1026",
    pages = "235--249",
}


@article{voita2020information,
  title={Information-Theoretic Probing with Minimum Description Length},
  author={Voita, Elena and Titov, Ivan},
  journal={arXiv preprint arXiv:2003.12298},
  year={2020}
}


@article{whitney2020evaluating,
  title={Evaluating representations by the complexity of learning low-loss predictors},
  author={Whitney, William F and Song, Min Jae and Brandfonbrener, David and Altosaar, Jaan and Cho, Kyunghyun},
  journal={arXiv preprint arXiv:2009.07368},
  year={2020}
}
